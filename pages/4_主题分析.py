import streamlit as st
import os
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
from utils import get_current_project_path, get_file_content, create_wordcloud
from bertopic_utils import BERTopicAnalyzer

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="ä¸»é¢˜åˆ†æ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# æ£€æŸ¥æ˜¯å¦æœ‰æ´»åŠ¨é¡¹ç›®
if 'current_project' not in st.session_state or not st.session_state.current_project:
    st.warning("è¯·å…ˆåœ¨é¦–é¡µé€‰æ‹©æˆ–åˆ›å»ºä¸€ä¸ªé¡¹ç›®")
    st.stop()

# é¡µé¢æ ‡é¢˜
st.title("ä¸»é¢˜åˆ†æ (BERTopic) ä»…æœ‰åŸºç¡€åŠŸèƒ½ï¼Œå¦‚éœ€è¦æ›´å¤šåŠŸèƒ½è¯·ä½¿ç”¨ä¸‹è½½ç•Œé¢çš„bertopicä¸“ç”¨å·¥å…·")
st.write(f"å½“å‰é¡¹ç›®: {st.session_state.current_project}")

# è·å–é¡¹ç›®è·¯å¾„
project_path = get_current_project_path()
files_dir = os.path.join(project_path, "files")
bertopic_results_path = os.path.join(project_path, "bertopic_results.json")

# æ£€æŸ¥æ–‡ä»¶ç›®å½•æ˜¯å¦å­˜åœ¨
if not os.path.exists(files_dir):
    st.error("æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨")
    st.stop()

# è·å–æ–‡ä»¶åˆ—è¡¨
files = [f for f in os.listdir(files_dir) if os.path.isfile(os.path.join(files_dir, f))]

if not files:
    st.error("é¡¹ç›®ä¸­æ²¡æœ‰æ–‡ä»¶ï¼Œè¯·å…ˆä¸Šä¼ æ–‡ä»¶")
    st.stop()

# åˆå§‹åŒ–BERTopicåˆ†æå™¨
@st.cache_resource
def get_bertopic_analyzer():
    return BERTopicAnalyzer()

analyzer = get_bertopic_analyzer()

# åˆ›å»ºé€‰é¡¹å¡
tab1, tab2, tab3 = st.tabs(["ä¸»é¢˜å»ºæ¨¡", "ä¸»é¢˜å¯è§†åŒ–", "ä¸»é¢˜è¯„ä¼°"])

# ä¸»é¢˜å»ºæ¨¡é€‰é¡¹å¡
with tab1:
    st.header("ä¸»é¢˜å»ºæ¨¡")
    
    # å‚æ•°è®¾ç½®
    with st.expander("å‚æ•°è®¾ç½®", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            num_topics = st.slider("ä¸»é¢˜æ•°é‡", 2, 20, 5)
            min_topic_size = st.slider("æœ€å°ä¸»é¢˜å¤§å°", 2, 20, 5)
        
        with col2:
            embedding_model = st.selectbox(
                "åµŒå…¥æ¨¡å‹",
                ["paraphrase-multilingual-MiniLM-L12-v2", "distiluse-base-multilingual-cased"]
            )
            
            stopwords_file = st.file_uploader("åœç”¨è¯æ–‡ä»¶ (å¯é€‰)", type=["txt"])
    
    # åŠ è½½åœç”¨è¯
    if stopwords_file:
        stopwords = []
        for line in stopwords_file:
            stopwords.append(line.decode("utf-8").strip())
        analyzer.load_stopwords(stopwords)
    else:
        analyzer.load_stopwords()
    
    # å¼€å§‹åˆ†ææŒ‰é’®
    if st.button("å¼€å§‹ä¸»é¢˜åˆ†æ"):
        # åŠ è½½æ–‡ä»¶å†…å®¹
        texts = []
        file_names = []
        
        with st.spinner("æ­£åœ¨åŠ è½½æ–‡ä»¶å†…å®¹..."):
            for file in files:
                file_path = os.path.join(files_dir, file)
                content = get_file_content(file_path)
                if content:
                    texts.append(content)
                    file_names.append(file)
        
        if not texts:
            st.error("æ²¡æœ‰å¯ç”¨çš„æ–‡æœ¬å†…å®¹")
        else:
            with st.spinner("æ­£åœ¨è¿›è¡Œä¸»é¢˜å»ºæ¨¡ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ..."):
                try:
                    # è®­ç»ƒæ¨¡å‹
                    topics, topic_info = analyzer.fit_transform(
                        texts, 
                        n_topics=num_topics,
                        min_topic_size=min_topic_size,
                        embedding_model_name=embedding_model
                    )
                    
                    # è·å–ä¸»é¢˜è¯
                    topic_words = analyzer.get_topic_words()
                    
                    # è·å–æ–‡æ¡£ä¸»é¢˜
                    doc_topics = analyzer.get_document_topics()
                    
                    # ä¿å­˜ç»“æœ
                    results = {
                        "topic_info": topic_info.to_dict() if topic_info is not None else None,
                        "topic_words": topic_words,
                        "doc_topics": doc_topics,
                        "file_names": file_names,
                        "params": {
                            "num_topics": num_topics,
                            "min_topic_size": min_topic_size,
                            "embedding_model": embedding_model
                        }
                    }
                    
                    with open(bertopic_results_path, 'w', encoding='utf-8') as f:
                        json.dump(results, f, ensure_ascii=False, indent=2)
                    
                    st.success("ä¸»é¢˜åˆ†æå®Œæˆ")
                    
                    # æ˜¾ç¤ºä¸»é¢˜è¯
                    st.subheader("ä¸»é¢˜å…³é”®è¯")
                    
                    for topic_id, words in topic_words.items():
                        st.write(f"**ä¸»é¢˜ {topic_id}**: " + ", ".join([f"{word} ({weight})" for word, weight in words]))
                    
                    # æ˜¾ç¤ºæ–‡æ¡£ä¸»é¢˜åˆ†å¸ƒ
                    st.subheader("æ–‡æ¡£ä¸»é¢˜åˆ†å¸ƒ")
                    
                    doc_topic_df = pd.DataFrame(doc_topics)
                    doc_topic_df["æ–‡ä»¶å"] = [file_names[i] for i in doc_topic_df["document_id"]]
                    doc_topic_df = doc_topic_df[["æ–‡ä»¶å", "topic_id"]]
                    doc_topic_df.columns = ["æ–‡ä»¶å", "ä¸»é¢˜ID"]
                    
                    st.dataframe(doc_topic_df)
                    
                except Exception as e:
                    st.error(f"ä¸»é¢˜åˆ†æå¤±è´¥: {str(e)}")

# ä¸»é¢˜å¯è§†åŒ–é€‰é¡¹å¡
with tab2:
    st.header("ä¸»é¢˜å¯è§†åŒ–")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†æç»“æœ
    if not os.path.exists(bertopic_results_path):
        st.info("è¯·å…ˆåœ¨ä¸»é¢˜å»ºæ¨¡é€‰é¡¹å¡ä¸­è¿›è¡Œä¸»é¢˜åˆ†æ")
    else:
        # åŠ è½½åˆ†æç»“æœ
        with open(bertopic_results_path, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        # æ˜¾ç¤ºå¯è§†åŒ–é€‰é¡¹
        viz_type = st.radio(
            "é€‰æ‹©å¯è§†åŒ–ç±»å‹",
            ["ä¸»é¢˜åˆ†å¸ƒ", "ä¸»é¢˜è¯äº‘", "ä¸»é¢˜ç½‘ç»œ"]
        )
        
        if viz_type == "ä¸»é¢˜åˆ†å¸ƒ":
            # åˆ›å»ºä¸»é¢˜åˆ†å¸ƒå›¾
            if "doc_topics" in results and results["doc_topics"]:
                doc_topics = results["doc_topics"]
                file_names = results["file_names"]
                
                # è®¡ç®—æ¯ä¸ªä¸»é¢˜çš„æ–‡æ¡£æ•°é‡
                topic_counts = {}
                for doc in doc_topics:
                    topic_id = doc["topic_id"]
                    if topic_id == -1:
                        topic_label = "å™ªå£°"
                    else:
                        topic_label = f"ä¸»é¢˜ {topic_id}"
                        
                    topic_counts[topic_label] = topic_counts.get(topic_label, 0) + 1
                
                # åˆ›å»ºæ•°æ®æ¡†
                df = pd.DataFrame({
                    "ä¸»é¢˜": list(topic_counts.keys()),
                    "æ–‡æ¡£æ•°é‡": list(topic_counts.values())
                })
                
                # åˆ›å»ºæ¡å½¢å›¾
                fig = px.bar(
                    df, 
                    x="ä¸»é¢˜", 
                    y="æ–‡æ¡£æ•°é‡", 
                    title="ä¸»é¢˜åˆ†å¸ƒ",
                    color="ä¸»é¢˜"
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # æ˜¾ç¤ºä¸»é¢˜æ–‡æ¡£åˆ—è¡¨
                st.subheader("å„ä¸»é¢˜æ–‡æ¡£åˆ—è¡¨")
                
                # æŒ‰ä¸»é¢˜åˆ†ç»„æ˜¾ç¤ºæ–‡æ¡£
                for topic_id in set([doc["topic_id"] for doc in doc_topics]):
                    if topic_id == -1:
                        topic_label = "å™ªå£°ä¸»é¢˜"
                    else:
                        topic_label = f"ä¸»é¢˜ {topic_id}"
                    
                    st.write(f"**{topic_label}**")
                    
                    # è·å–è¯¥ä¸»é¢˜çš„æ–‡æ¡£
                    topic_docs = [file_names[doc["document_id"]] for doc in doc_topics if doc["topic_id"] == topic_id]
                    
                    # æ˜¾ç¤ºæ–‡æ¡£åˆ—è¡¨
                    for doc in topic_docs:
                        st.write(f"- {doc}")
                    
                    st.write("")
            else:
                st.warning("æ²¡æœ‰å¯ç”¨çš„ä¸»é¢˜åˆ†å¸ƒæ•°æ®")
        
        elif viz_type == "ä¸»é¢˜è¯äº‘":
            # æ˜¾ç¤ºä¸»é¢˜è¯äº‘
            if "topic_words" in results and results["topic_words"]:
                topic_words = results["topic_words"]
                
                # é€‰æ‹©ä¸»é¢˜
                topic_ids = [int(tid) for tid in topic_words.keys()]
                selected_topic = st.selectbox("é€‰æ‹©ä¸»é¢˜", topic_ids)
                
                # åˆ›å»ºè¯äº‘
                if str(selected_topic) in topic_words:
                    words = topic_words[str(selected_topic)]
                    word_dict = {word: weight for word, weight in words}
                    
                    # ä½¿ç”¨è¯äº‘å¯è§†åŒ–
                    try:
                        # åˆ›å»ºè¯é¢‘å­—å…¸
                        word_freq = {word: weight for word, weight in words}
                        
                        # åˆ›å»ºè¯äº‘
                        from wordcloud import WordCloud
                        import matplotlib.pyplot as plt
                        from io import BytesIO
                        import base64
                        
                        wc = WordCloud(
                            font_path="simhei.ttf",  # éœ€è¦æœ‰ä¸­æ–‡å­—ä½“
                            width=800,
                            height=400,
                            background_color="white",
                            max_words=100
                        )
                        
                        wc.generate_from_frequencies(word_freq)
                        
                        # æ˜¾ç¤ºè¯äº‘
                        fig, ax = plt.subplots(figsize=(10, 5))
                        ax.imshow(wc, interpolation='bilinear')
                        ax.axis("off")
                        ax.set_title(f"ä¸»é¢˜ {selected_topic} è¯äº‘")
                        
                        st.pyplot(fig)
                        
                        # æ˜¾ç¤ºä¸»é¢˜è¯åˆ—è¡¨
                        st.subheader(f"ä¸»é¢˜ {selected_topic} å…³é”®è¯")
                        
                        # åˆ›å»ºå…³é”®è¯è¡¨æ ¼
                        word_df = pd.DataFrame(words, columns=["è¯è¯­", "æƒé‡"])
                        st.dataframe(word_df)
                        
                    except Exception as e:
                        st.error(f"åˆ›å»ºè¯äº‘å¤±è´¥: {str(e)}")
                        
                        # æ˜¾ç¤ºè¯è¡¨
                        st.write(f"ä¸»é¢˜ {selected_topic} å…³é”®è¯:")
                        for word, weight in words:
                            st.write(f"- {word}: {weight}")
                else:
                    st.warning(f"ä¸»é¢˜ {selected_topic} æ²¡æœ‰å¯ç”¨çš„è¯è¯­æ•°æ®")
            else:
                st.warning("æ²¡æœ‰å¯ç”¨çš„ä¸»é¢˜è¯æ•°æ®")
        
        elif viz_type == "ä¸»é¢˜ç½‘ç»œ":
            st.info("ä¸»é¢˜ç½‘ç»œå¯è§†åŒ–éœ€è¦ä½¿ç”¨BERTopicçš„å†…ç½®åŠŸèƒ½ï¼Œè¯·å…ˆåœ¨ä¸»é¢˜å»ºæ¨¡é€‰é¡¹å¡ä¸­è¿›è¡Œåˆ†æ")
            
            # å¦‚æœæ¨¡å‹å·²ç»è®­ç»ƒï¼Œæ˜¾ç¤ºä¸»é¢˜ç½‘ç»œ
            if hasattr(analyzer, 'model') and analyzer.model is not None:
                try:
                    # ä½¿ç”¨BERTopicçš„å¯è§†åŒ–åŠŸèƒ½
                    fig = analyzer.visualize_topics()
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"ä¸»é¢˜ç½‘ç»œå¯è§†åŒ–å¤±è´¥: {str(e)}")
            else:
                st.warning("è¯·å…ˆåœ¨ä¸»é¢˜å»ºæ¨¡é€‰é¡¹å¡ä¸­è¿›è¡Œåˆ†æ")

# ä¸»é¢˜è¯„ä¼°é€‰é¡¹å¡
with tab3:
    st.header("ä¸»é¢˜è¯„ä¼°")
    
    # ä¸»é¢˜æ•°é‡è¯„ä¼°
    st.subheader("ä¸»é¢˜æ•°é‡è¯„ä¼°")
    
    # å‚æ•°è®¾ç½®
    min_topics = st.slider("æœ€å°ä¸»é¢˜æ•°", 2, 10, 2)
    max_topics = st.slider("æœ€å¤§ä¸»é¢˜æ•°", 5, 30, 20)
    step = st.slider("æ­¥é•¿", 1, 5, 2)
    
    if st.button("è¯„ä¼°ä¸»é¢˜æ•°é‡"):
        # åŠ è½½æ–‡ä»¶å†…å®¹
        texts = []
        
        with st.spinner("æ­£åœ¨åŠ è½½æ–‡ä»¶å†…å®¹..."):
            for file in files:
                file_path = os.path.join(files_dir, file)
                content = get_file_content(file_path)
                if content:
                    texts.append(content)
        
        if not texts:
            st.error("æ²¡æœ‰å¯ç”¨çš„æ–‡æœ¬å†…å®¹")
        else:
            with st.spinner("æ­£åœ¨è¯„ä¼°ä¸»é¢˜æ•°é‡ï¼Œè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ..."):
                try:
                    # è¯„ä¼°ä¸»é¢˜æ•°é‡
                    fig, df = analyzer.evaluate_topics(
                        texts, 
                        topic_range=(min_topics, max_topics, step)
                    )
                    
                    if fig is not None:
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # æ˜¾ç¤ºè¯„ä¼°ç»“æœè¡¨æ ¼
                        st.subheader("è¯„ä¼°ç»“æœ")
                        st.dataframe(df)
                        
                        # æ‰¾å‡ºæœ€ä½³ä¸»é¢˜æ•°
                        best_num_topics = df.loc[df["ä¸€è‡´æ€§å¾—åˆ†"].idxmax(), "ä¸»é¢˜æ•°é‡"]
                        st.success(f"æ ¹æ®ä¸€è‡´æ€§å¾—åˆ†ï¼Œå»ºè®®çš„ä¸»é¢˜æ•°é‡ä¸º: {best_num_topics}")
                    else:
                        st.error("ä¸»é¢˜æ•°é‡è¯„ä¼°å¤±è´¥")
                except Exception as e:
                    st.error(f"ä¸»é¢˜æ•°é‡è¯„ä¼°å¤±è´¥: {str(e)}")
    
    # ä¸»é¢˜ç›¸ä¼¼åº¦åˆ†æ
    st.subheader("ä¸»é¢˜ç›¸ä¼¼åº¦åˆ†æ")
    
    if hasattr(analyzer, 'model') and analyzer.model is not None:
        similarity_threshold = st.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.5, 0.9, 0.7, 0.05)
        
        if st.button("åˆ†æä¸»é¢˜ç›¸ä¼¼åº¦"):
            with st.spinner("æ­£åœ¨åˆ†æä¸»é¢˜ç›¸ä¼¼åº¦..."):
                try:
                    # æŸ¥æ‰¾ç›¸ä¼¼ä¸»é¢˜
                    similar_topics = analyzer.find_similar_topics(threshold=similarity_threshold)
                    
                    if similar_topics:
                        st.subheader("ç›¸ä¼¼ä¸»é¢˜å¯¹")
                        
                        # åˆ›å»ºç›¸ä¼¼ä¸»é¢˜è¡¨æ ¼
                        similar_df = pd.DataFrame(similar_topics, columns=["ä¸»é¢˜1", "ä¸»é¢˜2", "ç›¸ä¼¼åº¦"])
                        st.dataframe(similar_df)
                        
                        # æ˜¾ç¤ºåˆå¹¶å»ºè®®
                        st.subheader("åˆå¹¶å»ºè®®")
                        st.write("ä»¥ä¸‹ä¸»é¢˜å¯èƒ½éœ€è¦åˆå¹¶:")
                        
                        for t1, t2, sim in similar_topics:
                            st.write(f"- ä¸»é¢˜ {t1} å’Œä¸»é¢˜ {t2} (ç›¸ä¼¼åº¦: {sim:.4f})")
                    else:
                        st.info(f"æ²¡æœ‰æ‰¾åˆ°ç›¸ä¼¼åº¦é«˜äº {similarity_threshold} çš„ä¸»é¢˜å¯¹")
                except Exception as e:
                    st.error(f"ä¸»é¢˜ç›¸ä¼¼åº¦åˆ†æå¤±è´¥: {str(e)}")
    else:
        st.info("è¯·å…ˆåœ¨ä¸»é¢˜å»ºæ¨¡é€‰é¡¹å¡ä¸­è¿›è¡Œåˆ†æ")

# é¡µè„š
st.markdown("---")
st.markdown("å†…å®¹åˆ†æå·¥å…· Â© 2023") 